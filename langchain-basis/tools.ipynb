{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98da0c91",
   "metadata": {},
   "source": [
    "Tools in Langchain\n",
    "1. how to create\n",
    "2. how to use built in tools and toolkits\n",
    "3. how to use chat models to call tools\n",
    "4. how to pass tool outputs to chat models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939c481d",
   "metadata": {},
   "source": [
    "This @tools decorator is the simplest way to define a custom tools. The decorator uses the function name as a tool name by default, but this can be overridden by passinf a string as a first argument. additionally, a decorator will be use the function's docstring as a tool's decription\n",
    "- so docstring must be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db18ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## @tool decorator\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def division(a:int,b:int)->int:\n",
    "    \"\"\"Divide 2 number\"\"\"\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86352d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division\n",
      "Divide 2 number\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(division.name)\n",
    "print(division.description)\n",
    "print(division.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e47421",
   "metadata": {},
   "outputs": [],
   "source": [
    "## async implementation\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d8f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,List\n",
    "\n",
    "@tool\n",
    "def multiply_by_max(\n",
    "    a: Annotated[int,\"A value\"],\n",
    "    b:Annotated[List[int],\"list of ints over which to take maximum\"]\n",
    ")->int:\n",
    "    \"\"\"Mulitply a by the maximum of b\"\"\"\n",
    "    return a* max(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a13e50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'description': 'A value', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'list of ints over which to take maximum', 'items': {'type': 'integer'}, 'title': 'B', 'type': 'array'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply_by_max.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a629c84b",
   "metadata": {},
   "source": [
    "### Structured Tool\n",
    "The StructuredTool.from_function class method provides a bit more configurability than the @tool decorator, without requiring much additional code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853b07d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "calculator=StructuredTool.from_function(func=multiply,coroutine=amultiply)\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(await calculator.ainvoke({\"a\": 2, \"b\": 7}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3845d",
   "metadata": {},
   "source": [
    "### Inbuilt tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e559ba",
   "metadata": {},
   "source": [
    "### wikipedia Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63996ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that stores and retrieves embeddings of data in v\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=5,doc_content_chars_max=500)\n",
    "tool=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(tool.invoke({\"query\":\"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a47ef75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c46e6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"]=os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc39e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    "    # include_answer=False,\n",
    "    # include_raw_content=False,\n",
    "    # include_images=False,\n",
    "    # include_image_descriptions=False,\n",
    "    # search_depth=\"basic\",\n",
    "    # time_range=\"day\",\n",
    "    # include_domains=None,\n",
    "    # exclude_domains=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da1f9870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the recent ai news',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.artificialintelligence-news.com/',\n",
       "   'title': 'AI News: Latest News, Analysis & Events',\n",
       "   'content': 'Gartner Data & Analytics Summit unveils expanded AI agenda for 2026 · Thailand becomes one of the first in Asia to get the Sora app · Malaysia launches Ryt Bank',\n",
       "   'score': 0.66777676,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.fastcompany.com/section/artificial-intelligence',\n",
       "   'title': 'Artificial Intelligence',\n",
       "   'content': \"Latest Artificial Intelligence News. TECH · Google's threat intel chief explains why AI is now both the weapon and the target. As rivals and nation-states try\",\n",
       "   'score': 0.66464967,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.wsj.com/tech/ai?gaa_at=eafs&gaa_n=AWEtsqf5kOcqF4hgdF19uCvYV1IgBfjRNdqtxQfW8qpogveUAsP_Sw626NwV&gaa_ts=6997fd89&gaa_sig=YsxnceAAopNMih0t5VXcFN7ZRfp2blbrikWqyZDEMiCteWeNGDsMQhJb8cLMj62ZEVLxxJzLThjyfhD5Y8l3-Q%3D%3D',\n",
       "   'title': 'Artificial Intelligence - Latest AI News and Analysis',\n",
       "   'content': \"Artificial Intelligence · India's Reliance Industries to Invest $110 Billion in AI · Tata Group and OpenAI Form Partnership, to Develop AI Data Centers · How to\",\n",
       "   'score': 0.6410185,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.reuters.com/technology/artificial-intelligence/',\n",
       "   'title': 'AI News | Latest Headlines and Developments',\n",
       "   'content': \"Artificial Intelligence · 3 hours ago. Bill Gates cancels appearance at India AI summit amid Epstein scrutiny · 9 hours ago. Modi's AI unity pose turns awkward\",\n",
       "   'score': 0.61112726,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.nbcnews.com/artificial-intelligence',\n",
       "   'title': 'Artificial intelligence news: Chat AI, ChatGPT and Bard',\n",
       "   'content': \"The latest news and top stories on artificial intelligence, including AI chatbots like Microsoft's ChatGPT, Apple's AI Chatbot and Google's Bard.\",\n",
       "   'score': 0.60386235,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.81,\n",
       " 'request_id': '2b4c9a39-b6a0-4fbf-b34d-16010b2fa564'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke(\"What is the recent ai news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f298d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2023-08-02\\nTitle: Attention Is All You Need\\nAuthors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\\nSummary: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "tool=ArxivAPIWrapper()\n",
    "\n",
    "tool.run(\"1706.03762\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9849166",
   "metadata": {},
   "source": [
    "### Call Tool With LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17266f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(wiki_tool.invoke({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefa3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    "    # include_answer=False,\n",
    "    # include_raw_content=False,\n",
    "    # include_images=False,\n",
    "    # include_image_descriptions=False,\n",
    "    # search_depth=\"basic\",\n",
    "    # time_range=\"day\",\n",
    "    # include_domains=None,\n",
    "    # exclude_domains=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ec4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fd328a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01941486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "add.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47555ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "multiply.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03b8fa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tavily_search'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dbd2924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools=[wiki_tool,add,multiply,tavily_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98107f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\langchain_tutorials\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=100)),\n",
       " StructuredTool(name='add', description='Adds a and b.', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x00000228E309B060>),\n",
       " StructuredTool(name='multiply', description='Multiplies a and b.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x00000228E309B100>),\n",
       " TavilySearch(max_results=5, topic='general', api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d11619e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000228E33994D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000228E3504050>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm=init_chat_model(\"qwen/qwen3-32b\",model_provider=\"groq\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be4042f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000228E33994D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000228E3504050>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'Adds a and b.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'Multiplies a and b.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced', 'fast', 'ultra-fast'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        \\n        Use \"fast\" for optimized low latency with high relevance.\\n        \\n        Use \"ultra-fast\" when latency is prioritized above all else.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool=llm.bind_tools(tools)\n",
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e218f563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'reasoning_content': 'Okay, let\\'s see. The user is asking \"What is 2* 3\". First, I need to figure out what they\\'re asking. The asterisk (*) is a multiplication symbol, so they want to know the product of 2 and 3.\\n\\nLooking at the tools provided, there\\'s a multiply function. The description says it multiplies a and b, both integers. The parameters require a and b as integers. So I should use this function here.\\n\\nThe user input is straightforward. The numbers are 2 and 3. I need to call the multiply function with a=2 and b=3. There\\'s no need for any other tools here because it\\'s a simple arithmetic problem.\\n\\nI should check if there\\'s any hidden complexity, like if the user meant something else, but the question seems direct. No need for Wikipedia or Tavily Search. The answer is 6, so the function call should return that.\\n', 'tool_calls': [{'id': '0tgspv6rx', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 1937, 'total_tokens': 2158, 'completion_time': 0.425264435, 'completion_tokens_details': {'reasoning_tokens': 192}, 'prompt_time': 0.101471134, 'prompt_tokens_details': None, 'queue_time': 0.047137946, 'total_time': 0.526735569}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019c79aa-d85d-7681-a15c-996479e13672-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '0tgspv6rx', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 1937, 'output_tokens': 221, 'total_tokens': 2158, 'output_token_details': {'reasoning': 192}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "query=\"What is 2* 3\"\n",
    "messages = [HumanMessage(query)]\n",
    "response=llm_with_tool.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4912cff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, let\\'s see. The user is asking \"What is 2* 3\". First, I need to figure out what they\\'re asking. The asterisk (*) is a multiplication symbol, so they want to know the product of 2 and 3.\\n\\nLooking at the tools provided, there\\'s a multiply function. The description says it multiplies a and b, both integers. The parameters require a and b as integers. So I should use this function here.\\n\\nThe user input is straightforward. The numbers are 2 and 3. I need to call the multiply function with a=2 and b=3. There\\'s no need for any other tools here because it\\'s a simple arithmetic problem.\\n\\nI should check if there\\'s any hidden complexity, like if the user meant something else, but the question seems direct. No need for Wikipedia or Tavily Search. The answer is 6, so the function call should return that.\\n', 'tool_calls': [{'id': '0tgspv6rx', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 1937, 'total_tokens': 2158, 'completion_time': 0.425264435, 'completion_tokens_details': {'reasoning_tokens': 192}, 'prompt_time': 0.101471134, 'prompt_tokens_details': None, 'queue_time': 0.047137946, 'total_time': 0.526735569}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c79aa-d85d-7681-a15c-996479e13672-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '0tgspv6rx', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1937, 'output_tokens': 221, 'total_tokens': 2158, 'output_token_details': {'reasoning': 192}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5dac09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': '0tgspv6rx',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4105087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 2* 3', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='6', name='multiply', tool_call_id='0tgspv6rx')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply,\"wikipedia\":wiki_tool,\"tavily_search\":tavily_tool}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "847a9ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 2* 3', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='6', name='multiply', tool_call_id='0tgspv6rx')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9798f8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of multiplying 2 by 3 is **6**.', additional_kwargs={'reasoning_content': 'Okay, the user asked \"What is 2* 3\". Let me see. The tools available include a Wikipedia wrapper, an add function, a multiply function, and a Tavily search engine. The user is asking for the product of 2 and 3. Since there\\'s a multiply function, I should use that. The parameters for multiply are a and b, both integers. So, a is 2 and b is 3. I need to call the multiply function with these values. The answer should be 6. Let me make sure there\\'s no trick here, but 2 multiplied by 3 is straightforward. The other tools aren\\'t needed here because it\\'s a simple math problem. The response from the tool was 6, so I just need to present that as the answer.\\n'}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 1947, 'total_tokens': 2131, 'completion_time': 0.367032235, 'completion_tokens_details': {'reasoning_tokens': 165}, 'prompt_time': 0.097847749, 'prompt_tokens_details': None, 'queue_time': 0.04641904, 'total_time': 0.464879984}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c79ab-78ea-7e82-9cff-4db6334cffab-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1947, 'output_tokens': 184, 'total_tokens': 2131, 'output_token_details': {'reasoning': 165}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1e0c7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking two separate questions here. First, \"What is langchain?\" and second, \"what is 5*15?\" Let me break this down.\\n\\nFor the first part, \"langchain\" probably refers to a company or a technology. Since it\\'s a general knowledge question, I should use the Wikipedia function to get an accurate description. The user might be asking about the company LangChain, which I think is involved in AI or blockchain. I\\'ll need to look that up.\\n\\nThen, the second part is a math problem: 5 multiplied by 15. That\\'s straightforward arithmetic. The multiply function is available, so I can use that. The parameters are integers, so I just need to pass a=5 and b=15.\\n\\nWait, do I need to check if \"langchain\" is a common term or if there\\'s a specific article? Maybe there\\'s a Wikipedia page for LangChain. Also, I should make sure there\\'s no confusion with similar names. Once I get the info from Wikipedia, I can summarize it for the user.\\n\\nFor the math part, the multiply function should return 75. No issues there. I\\'ll need to call both functions and then present the answers clearly. Let me structure the response by first addressing what LangChain is and then providing the multiplication result.\\n', 'tool_calls': [{'id': '03dbgkv2m', 'function': {'arguments': '{\"query\":\"LangChain\"}', 'name': 'wikipedia'}, 'type': 'function'}, {'id': 'b49r77h2r', 'function': {'arguments': '{\"a\":5,\"b\":15}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 325, 'prompt_tokens': 1943, 'total_tokens': 2268, 'completion_time': 0.66200782, 'completion_tokens_details': {'reasoning_tokens': 274}, 'prompt_time': 0.095757162, 'prompt_tokens_details': None, 'queue_time': 0.049312448, 'total_time': 0.757764982}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c79ab-b42a-7cd2-9a09-1cea7fbd378a-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'LangChain'}, 'id': '03dbgkv2m', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 5, 'b': 15}, 'id': 'b49r77h2r', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1943, 'output_tokens': 325, 'total_tokens': 2268, 'output_token_details': {'reasoning': 274}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is langchain and what is 5*15?\"\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tool.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a725a27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': 'LangChain'},\n",
       "  'id': '03dbgkv2m',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'multiply',\n",
       "  'args': {'a': 5, 'b': 15},\n",
       "  'id': 'b49r77h2r',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dd6eb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is langchain and what is 5*15?', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of ', name='wikipedia', tool_call_id='03dbgkv2m'),\n",
       " ToolMessage(content='75', name='multiply', tool_call_id='b49r77h2r')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply,\"wikipedia\":wiki_tool,\"tavily_search\":tavily_tool}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd671554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response=llm_with_tool.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eea06906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a software framework designed to facilitate the integration and orchestration of various tools, models, and data sources, enabling developers to build complex workflows and applications. It provides abstractions for tasks like retrieval-augmented generation, agent-based workflows, and multi-step pipelines. For more details, you can explore its Wikipedia page.\\n\\nAdditionally, $5 \\\\times 15 = 75$.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96fbba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, let\\'s break down the user\\'s query. They asked three things: what is LangChain, calculate 5*15, and summarize recent AI news. \\n\\nFirst, for LangChain, I need to explain what it is. Since it\\'s a tool or framework, maybe Wikipedia has a good overview. I should use the wikipedia function with a query like \"LangChain\".\\n\\nNext, the math problem 5*15. That\\'s straightforward multiplication. The multiply function can handle this. The parameters would be a=5 and b=15.\\n\\nLastly, the recent AI news. This requires current information, so the tavily_search function is appropriate. The query would be \"recent AI news\". I should set the time_range to \"week\" to get the latest updates. Also, maybe set include_images to false since the user wants a summary, not images.\\n\\nWait, do I need to check if all functions are necessary? The user wants three separate pieces of info, so each should be handled by a different function. Let me make sure the parameters for tavily_search are correct. Time_range is \"week\" for recent news, and maybe topic as \"general\" unless specified, but the user mentioned AI, which is general. Okay, that should work. \\n\\nSo three tool calls: wikipedia for LangChain, multiply for 5*15, and tavily_search for recent AI news with time_range set to week.\\n', 'tool_calls': [{'id': '7nvvptnw5', 'function': {'arguments': '{\"query\":\"LangChain\"}', 'name': 'wikipedia'}, 'type': 'function'}, {'id': 'a6at66jar', 'function': {'arguments': '{\"a\":5,\"b\":15}', 'name': 'multiply'}, 'type': 'function'}, {'id': 't96ekfb21', 'function': {'arguments': '{\"query\":\"recent AI news\",\"search_depth\":\"advanced\",\"time_range\":\"week\"}', 'name': 'tavily_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 382, 'prompt_tokens': 1949, 'total_tokens': 2331, 'completion_time': 0.787743839, 'completion_tokens_details': {'reasoning_tokens': 293}, 'prompt_time': 0.096726713, 'prompt_tokens_details': None, 'queue_time': 0.159890377, 'total_time': 0.884470552}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c79ac-523a-78b3-8389-b23ff048a041-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'LangChain'}, 'id': '7nvvptnw5', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 5, 'b': 15}, 'id': 'a6at66jar', 'type': 'tool_call'}, {'name': 'tavily_search', 'args': {'query': 'recent AI news', 'search_depth': 'advanced', 'time_range': 'week'}, 'id': 't96ekfb21', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 1949, 'output_tokens': 382, 'total_tokens': 2331, 'output_token_details': {'reasoning': 293}})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is langchain and what is 5*15 and summarize the recent AI news ?\"\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tool.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47b8907f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': 'LangChain'},\n",
       "  'id': '7nvvptnw5',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'multiply',\n",
       "  'args': {'a': 5, 'b': 15},\n",
       "  'id': 'a6at66jar',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search',\n",
       "  'args': {'query': 'recent AI news',\n",
       "   'search_depth': 'advanced',\n",
       "   'time_range': 'week'},\n",
       "  'id': 't96ekfb21',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fce4ed76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is langchain and what is 5*15 and summarize the recent AI news ?', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of ', name='wikipedia', tool_call_id='7nvvptnw5'),\n",
       " ToolMessage(content='75', name='multiply', tool_call_id='a6at66jar'),\n",
       " ToolMessage(content='{\"query\": \"recent AI news\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.artificialintelligence-news.com/\", \"title\": \"AI News | Latest News | Insights Powering AI-Driven Business Growth\", \"content\": \"### PepsiCo is using AI to rethink how factories are designed and updated\\\\n\\\\nAI Business Strategy, Deep Dives, Featured News, Features, Governance, Regulation & Policy, Inside AI\\\\n\\\\n### Meeting the new ETSI standard for AI security\\\\n\\\\n## Latest\\\\n\\\\nAI Business Strategy\\\\n\\\\nFebruary 18, 2026\\\\n\\\\n# Infosys AI implementation framework offers business leaders guidance\\\\n\\\\nTechEx Events\\\\n\\\\nFebruary 17, 2026\\\\n\\\\n# SS&C Blue Prism: On the journey from RPA to agentic automation\\\\n\\\\nFinance AI\\\\n\\\\nFebruary 17, 2026\\\\n\\\\n# Insurance giant AIG deploys agentic AI with orchestration layer\\\\n\\\\nAlibaba mascot as the release of Alibaba\\'s latest Qwen model challenges proprietary AI model economics with comparable performance on commodity hardware.\\\\n\\\\nOpen-Source & Democratised AI\\\\n\\\\nFebruary 17, 2026 [...] # How to Calculate Business Value and Cost for Generative AI Use Cases\\\\n\\\\n# Gartner Data & Analytics Summit unveils expanded AI agenda for 2026\\\\n\\\\n#### Applications\\\\n\\\\n### Thailand becomes one of the first in Asia to get the Sora app\\\\n\\\\nEntertainment & Media\\\\n\\\\nOctober 30, 2025\\\\n\\\\n### Malaysia launches Ryt Bank, its first AI-powered bank\\\\n\\\\nFinance AI\\\\n\\\\nAugust 26, 2025\\\\n\\\\n### Google’s Veo 3 AI video creation tools are now widely available\\\\n\\\\nAI in Action\\\\n\\\\nJuly 29, 2025\\\\n\\\\n#### Computer Vision\\\\n\\\\n### US and Japan announce sweeping AI and tech collaboration\\\\n\\\\nArtificial Intelligence\\\\n\\\\nApril 11, 2024\\\\n\\\\n### UK and Canada sign AI compute agreement\\\\n\\\\nArtificial Intelligence\\\\n\\\\nJanuary 31, 2024\\\\n\\\\n### Quantum AI represents a ‘transformative advancement’\\\\n\\\\nAI Hardware & Chips\\\\n\\\\nNovember 14, 2023\\\\n\\\\n#### Machine Learning [...] TechEx Events\\\\n\\\\nFebruary 17, 2026\\\\n\\\\n### AI use surges at Travelers as call centre roles reduce\\\\n\\\\nAI Business Strategy\\\\n\\\\nJanuary 30, 2026\\\\n\\\\n### Cold snap highlight’s airlines’ proactive use of AI\\\\n\\\\nService Industry AI\\\\n\\\\nJanuary 27, 2026\\\\n\\\\n#### Deep Learning\\\\n\\\\n### IBM Research unveils breakthrough analog AI chip for efficient deep learning\\\\n\\\\nAI Market Trends\\\\n\\\\nAugust 11, 2023\\\\n\\\\n### Damian Bogunowicz, Neural Magic: On revolutionising deep learning with CPUs\\\\n\\\\nAI Market Trends\\\\n\\\\nJuly 24, 2023\\\\n\\\\n### OpenAI’s GPT-3 is a convincing philosopher\\\\n\\\\nAI Market Trends\\\\n\\\\nJuly 27, 2022\\\\n\\\\n## Subscribe\\\\n\\\\nAll our premium content and latest tech news delivered straight to your inbox\\\\n\\\\n## Resources\\\\n\\\\nResource\\\\n\\\\nJanuary 8, 2026\", \"score\": 0.99444515, \"raw_content\": null}, {\"url\": \"https://www.sciencedaily.com/news/computers_math/artificial_intelligence/\", \"title\": \"Artificial Intelligence News - ScienceDaily\", \"content\": \"ScienceDaily\\\\n\\\\n# Artificial Intelligence News\\\\n\\\\n## Top Headlines\\\\n\\\\n## Latest Headlines\\\\n\\\\n## Earlier Headlines\\\\n\\\\n### Monday, December 8, 2025\\\\n\\\\n### Friday, November 28, 2025\\\\n\\\\n### Sunday, November 16, 2025\\\\n\\\\n### Wednesday, November 5, 2025\\\\n\\\\n### Tuesday, October 28, 2025\\\\n\\\\n### Wednesday, October 22, 2025\\\\n\\\\n### Monday, October 13, 2025\\\\n\\\\n### Thursday, October 9, 2025\\\\n\\\\n### Tuesday, October 14, 2025\\\\n\\\\n### Saturday, October 4, 2025\\\\n\\\\n### Sunday, September 28, 2025\\\\n\\\\n### Thursday, September 25, 2025\\\\n\\\\n### Wednesday, September 24, 2025\\\\n\\\\n### Sunday, September 21, 2025\\\\n\\\\n### Friday, November 14, 2025\\\\n\\\\n### Sunday, September 7, 2025\\\\n\\\\n### Friday, August 22, 2025\\\\n\\\\n### Wednesday, August 27, 2025\\\\n\\\\n### Wednesday, August 13, 2025\\\\n\\\\n### Saturday, November 1, 2025\\\\n\\\\n### Friday, July 25, 2025\\\\n\\\\n### Thursday, July 24, 2025 [...] ### Friday, July 25, 2025\\\\n\\\\n### Thursday, July 24, 2025\\\\n\\\\n### Tuesday, July 8, 2025\\\\n\\\\n### Wednesday, July 2, 2025\\\\n\\\\n### Sunday, August 24, 2025\\\\n\\\\n### Wednesday, June 25, 2025\\\\n\\\\n### Sunday, June 22, 2025\\\\n\\\\n### Thursday, June 26, 2025\\\\n\\\\n### Monday, June 30, 2025\\\\n\\\\n### Thursday, June 19, 2025\\\\n\\\\n### Sunday, June 22, 2025\\\\n\\\\n### Monday, June 16, 2025\\\\n\\\\n### Sunday, June 8, 2025\\\\n\\\\n### Saturday, August 16, 2025\\\\n\\\\n### Saturday, June 7, 2025\\\\n\\\\n### Tuesday, June 3, 2025\\\\n\\\\n### Monday, June 2, 2025\\\\n\\\\n### Friday, May 30, 2025\\\\n\\\\n### Wednesday, May 28, 2025\\\\n\\\\n### Tuesday, May 27, 2025\\\\n\\\\n### Thursday, May 22, 2025\\\\n\\\\n### Wednesday, May 21, 2025\\\\n\\\\n### Monday, May 19, 2025\\\\n\\\\n### Thursday, May 15, 2025\\\\n\\\\n### Wednesday, May 14, 2025\\\\n\\\\n### Tuesday, May 13, 2025\\\\n\\\\n### Monday, May 12, 2025\\\\n\\\\n### Thursday, May 8, 2025 [...] ### Monday, May 12, 2025\\\\n\\\\n### Thursday, May 8, 2025\\\\n\\\\n### Wednesday, May 7, 2025\\\\n\\\\n### Tuesday, May 6, 2025\\\\n\\\\n### Monday, May 5, 2025\\\\n\\\\n### Thursday, May 1, 2025\\\\n\\\\n### Wednesday, April 30, 2025\\\\n\\\\n### Monday, April 28, 2025\\\\n\\\\n### Friday, April 25, 2025\\\\n\\\\n### Thursday, April 24, 2025\\\\n\\\\n### Wednesday, April 23, 2025\\\\n\\\\n## Breaking\\\\n\\\\n## Trending Topics\\\\n\\\\n## Strange & Offbeat\\\\n\\\\nStay informed with ScienceDaily\\'s free email newsletter, updated daily and weekly. Or view our many newsfeeds in your RSS reader:\\\\n\\\\nKeep up to date with the latest news from ScienceDaily via social networks:\\\\n\\\\nTell us what you think of ScienceDaily -- we welcome both positive and negative comments. Have any problems using the site? Questions?\", \"score\": 0.96124375, \"raw_content\": null}, {\"url\": \"https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-collection/\", \"title\": \"AI Impact Summit 2026 - Google Blog\", \"content\": \"A $30 million AI for Science Impact Challenge to support researchers globally who are using AI to drive scientific breakthroughs.\\\\n Our 2026 Responsible AI Progress Report\\\\n\\\\n  Our latest Responsible AI Progress Report shares how we’re applying our AI Principles to the development of our products and research.\\\\n Announcing our new climate tech collaboration in India\\\\n\\\\n  In collaboration with the Office of the Principal Scientific Advisor we’ve launched the Google Center for Climate Technology.\\\\n\\\\nLet’s stay in touch. Get the latest news from Google in your inbox.\\\\n\\\\nSubscribe [...] An overview of Google’s new global partnerships and funding announcements at the AI Impact Summit in India.\\\\n Announcing America-India Connect fiber-optic routes\\\\n\\\\n  New fiber-optic routes will increase digital connectivity between the U.S., India and locations across the Southern Hemisphere.\\\\n Introducing our National Partnerships for AI & collaboration in India\\\\n\\\\n  Google DeepMind announces new partnerships in India to advance science, empower students and support agriculture and renewable energy.\\\\n Google.org Impact Challenge: AI for Government Innovation\\\\n\\\\n  This is a global call for organizations building AI-powered solutions that transform public services and drive societal impact.\\\\n Google.org Impact Challenge: AI for Science [...] The Keyword\\\\n\\\\nAI Impact Summit 2026\\\\n\\\\n[\\\\\"What does AI mean for retail?\\\\\", \\\\\"How did Nano Banana get its name?\\\\\", \\\\\"How can AI help me plan travel?\\\\\"]\\\\n\\\\nSubscribe\\\\n\\\\nShare\\\\n\\\\nx.com Facebook LinkedIn Mail\\\\n\\\\n# AI Impact Summit 2026\\\\n\\\\n8 articles \\\\n\\\\narticles 8\\\\n\\\\n8 articles \\\\n\\\\narticles 8\\\\n\\\\nOur last decade of breakthroughs in AI are helping us make progress against some of humanity’s biggest challenges. At the AI Impact Summit in India, we’re launching new global partnerships, research, investment and innovation, to ensure that these benefits are accessible for everyone.\\\\n\\\\n A message from our CEO  “No technology has me dreaming bigger than AI”\\\\n\\\\n  CEO Sundar Pichai’s remarks at the opening ceremony of the AI Impact Summit 2026\\\\n\\\\n  By Sundar Pichai - Feb 19, 2026\\\\n How we’re partnering to make AI work for everyone\", \"score\": 0.8539127, \"raw_content\": null}, {\"url\": \"https://www.theguardian.com/technology/artificialintelligenceai\", \"title\": \"AI (artificial intelligence) | The Guardian\", \"content\": \"## AI (artificial intelligence)\\\\n\\\\n## 19 February 2026\\\\n\\\\nJulie Sweet, CEO of Accenture, speaks at the AI Impact Summit in Delhi, India, on 19 February.\\\\n\\\\n### Accenture ‘links staff promotions to use of AI tools’\\\\n\\\\nAI chatbots Apps in Spain - 4 Nov 2026Mandatory Credit: Photo by Davide Bonaldo/SOPA Images/Shutterstock (16514507k)\\\\nIn this photo illustration, the apps of various AI chatbots, including Perplexity, Claude, Chat GPT, Gemini and Mistral, seen displayed on a smartphone.\\\\nAI chatbots Apps in Spain - 4 Nov 2026\\\\n\\\\n### Tell us: have you ever used AI to navigate everyday life and social relationships?\\\\n\\\\nKaleidoscopic animation featuring Martin Luther King Jr., Beyoncé, and a cartoon crow from Dumbo, arranged in a symmetrical pattern\", \"score\": 0.69097626, \"raw_content\": null}, {\"url\": \"https://www.theglobeandmail.com/investing/markets/markets-news/Motley%20Fool/317257/forget-the-noise-here-s-why-i-m-still-bullish-on-ai-stocks-for-2026/\", \"title\": \"Forget the Noise: Here\\'s Why I\\'m Still Bullish on AI Stocks for 2026\", \"content\": \"It would be easy to throw in the towel on artificial intelligence (AI) stocks. Not only have they (as a group) gone nowhere since October 2025, several of the technology industry\\'s stalwarts, including Microsoft and Oracle, have been struggling since reporting last quarter\\'s earnings. Investors are starting to wonder if these companies will ever be able to justify the massive investments they\\'re making in AI.\\\\n\\\\nAnd this concern isn\\'t without its merits. A survey performed by PwC earlier this year indicates that over half the world\\'s corporate CEOs haven\\'t yet seen any measurable benefit to utilizing Ai, while a study done by MIT suggests that, as of last year, 95% of generative AI projects didn\\'t provide any net return on the investment. Not good. [...] ## \\\\n\\\\n## Latest in\\\\n\\\\n## More\\\\n\\\\n# Forget the Noise: Here\\'s Why I\\'m Still Bullish on AI Stocks for 2026\\\\n\\\\n## Key Points\\\\n\\\\nAs has been the case with countless other new technologies, AI investors got a little ahead of themselves.\\\\n\\\\nThe adjustment of expectations now underway, however, isn\\'t an indictment of AI\\'s long-term potential.\\\\n\\\\nInvestors should start thinking now about which companies are in a position to do something actually constructive with artificial intelligence tech. [...] Will AI create the world\\'s first trillionaire? Our team just released a report on the one little-known company, called an \\\\\"Indispensable Monopoly\\\\\" providing the critical technology Nvidia and Intel both need. Continue »\\\\n\\\\nA person sitting at a desk reviewing paperwork.\\\\n\\\\nImage source: Getty Images.\\\\n\\\\nBut it certainly wouldn\\'t be the first time a new business idea ultimately didn\\'t live up to the hype. Think meal kits, or non-fungible tokens (NFTs).\\\\n\\\\nArtificial intelligence stocks aren\\'t doomed, however. That\\'s because AI has true enduring value. The crowd just needs to adjust its lofty expectations. These stocks will struggle in the meantime while they\\'re rethinking what these tickers are actually worth now, and what they can plausibly be worth in the foreseeable future.\", \"score\": 0.51952136, \"raw_content\": null}], \"response_time\": 3.14, \"request_id\": \"e31348a8-de16-4797-ba51-7373f1bc9bfe\"}', name='tavily_search', tool_call_id='t96ekfb21')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply,\"wikipedia\":wiki_tool,\"tavily_search\":tavily_tool}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fed7e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. **LangChain**: A software framework designed to integrate AI components, enabling developers to build applications using large language models (LLMs) and other AI tools. It provides a structured way to connect, manage, and orchestrate AI workflows.\\n\\n2. **5*15**: $ 5 \\\\times 15 = 75 $.\\n\\n3. **Recent AI News Summary**:\\n   - **PepsiCo** is leveraging AI to redesign and optimize factory operations.\\n   - **ETSI** (European Telecommunications Standards Institute) has introduced new standards for AI security.\\n   - **Google** announced global partnerships and AI initiatives in India, including the Google Center for Climate Technology and fiber-optic connectivity projects.\\n   - **Accenture** is linking employee promotions to the use of AI tools, reflecting growing industry adoption.\\n   - **AI Market Trends**: Mixed performance in AI stocks (e.g., Microsoft, Oracle) due to unmet ROI expectations for generative AI projects, though long-term potential remains bullish.\\n   - **International Collaborations**: The U.S. and Japan announced a sweeping tech collaboration, while the UK and Canada signed an AI compute agreement.\\n   - **Challenges**: Surveys indicate over 50% of CEOs have not yet seen measurable benefits from AI, and 95% of generative AI projects lack ROI.\\n\\nFor deeper details, refer to [AI News](https://www.artificialintelligence-news.com/) or [Google's AI Impact Summit](https://blog.google/innovation-and-ai/technology/ai/ai-impact-summit-2026-collection/).\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=llm_with_tool.invoke(messages)\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7af8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
